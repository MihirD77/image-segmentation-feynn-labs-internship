{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UHWRby_uF7iQ"
      },
      "outputs": [],
      "source": [
        "# Importing required libraries\n",
        "import numpy as np\n",
        "import os\n",
        "import cv2\n",
        "import tensorflow as tf\n",
        "from glob import glob\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "IMAGE_SIZE = 256\n",
        "BATCH_SIZE = 4\n",
        "NUM_CLASSES = 29"
      ],
      "metadata": {
        "id": "-pol1qpHUivQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Mounting the Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "HArfVxSWcw1w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing the datasets\n",
        "train_path='/content/drive/MyDrive/cityscapes_data/train'\n",
        "validation_path='/content/drive/MyDrive/cityscapes_data/val'\n",
        "train_images=[]\n",
        "train_masks=[]\n",
        "val_images=[]\n",
        "val_masks=[]"
      ],
      "metadata": {
        "id": "tpxiPe8NUmt8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Color pallete with 29 different colors\n",
        "color_palette= np.array([\n",
        "    [0, 0, 0],\n",
        "    [111, 74, 0],\n",
        "    [81, 0, 81],\n",
        "    [128, 64, 128],\n",
        "    [244, 35, 232],\n",
        "    [250, 170, 160],\n",
        "    [230, 150, 140],\n",
        "    [70, 70, 70],\n",
        "    [102, 102, 156],\n",
        "    [190, 153, 153],\n",
        "    [180, 165, 180],\n",
        "    [150, 100, 100],\n",
        "    [150, 120, 90],\n",
        "    [153, 153, 153],\n",
        "    [250, 170, 30],\n",
        "    [220, 220, 0],\n",
        "    [107, 142, 35],\n",
        "    [152, 251, 152],\n",
        "    [70, 130, 180],\n",
        "    [220, 20, 60],\n",
        "    [255, 0, 0],\n",
        "    [0, 0, 142],\n",
        "    [0, 0, 70],\n",
        "    [0, 60, 100],\n",
        "    [0, 0, 90],\n",
        "    [0, 0, 110],\n",
        "    [0, 80, 100],\n",
        "    [0, 0, 230],\n",
        "    [119, 11, 32],\n",
        "    ])"
      ],
      "metadata": {
        "id": "DY1JaiXaUrhp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Image processing of the dataset\n",
        "def getLabel(img):\n",
        "    \"\"\"turn a 3 channel RGB image to 1 channel index image\"\"\"\n",
        "    height, width, channel = img.shape\n",
        "    m_label = np.zeros((height, width, 1), dtype=np.uint8)\n",
        "    for w in range(width):\n",
        "        for h in range(height):\n",
        "            blue, green, red = img[h, w, :]\n",
        "            m_label[h, w, :]=np.argmin(np.linalg.norm(np.array([red, green, blue])-color_palette,axis=1),axis=0)\n",
        "    return m_label\n",
        "\n",
        "    return one_hot_mask.numpy()\n",
        "\n",
        "def loadImages(path, max):\n",
        "    temp_image, temp_masks=[],[]\n",
        "    images = glob(os.path.join(path,'*.jpg'))\n",
        "    count = 0\n",
        "    for i in tqdm(images):\n",
        "        if count < max:\n",
        "            i = cv2.imread(i)\n",
        "            image = i[:, :256]\n",
        "            image = cv2.normalize(image, None, 0, 1, cv2.NORM_MINMAX, cv2.CV_32F)\n",
        "            mask = i[:, 256:]\n",
        "            label = getLabel(mask)\n",
        "            temp_masks.append(label)\n",
        "            temp_image.append(image)\n",
        "            count+=1\n",
        "    return np.array(temp_image),np.array(temp_masks)"
      ],
      "metadata": {
        "id": "hez0bcXyUx4Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training the Model\n",
        "def dataGenerator(image, mask):\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((image, mask))\n",
        "    dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)\n",
        "    return dataset\n",
        "\n",
        "train_images, train_masks = loadImages(train_path,MAX=500)\n",
        "val_images, val_masks = loadImages(validation_path,MAX=50)\n",
        "\n",
        "\n",
        "train_dataset = dataGenerator(train_images, train_masks)\n",
        "validation_dataset = dataGenerator(val_images, val_masks)\n",
        "print(\"Train Dataset:\", train_dataset)\n",
        "print(\"Val Dataset:\", validation_dataset)\n",
        "\n",
        "def convolutionBlock(block_input, num_filters=256, kernel_size=3, dilation_rate=1, padding=\"same\", use_bias=False,):\n",
        "    x = layers.Conv2D(num_filters, kernel_size=kernel_size, dilation_rate=dilation_rate, padding=\"same\", use_bias=use_bias, kernel_initializer=keras.initializers.HeNormal(),)(block_input)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    return tf.nn.relu(x)\n",
        "\n",
        "\n",
        "def DilatedSpatialPyramidPooling(dspp_input):\n",
        "    dims = dspp_input.shape\n",
        "    x = layers.AveragePooling2D(pool_size=(dims[-3], dims[-2]))(dspp_input)\n",
        "    x = convolutionBlock(x, kernel_size=1, use_bias=True)\n",
        "    out_pool = layers.UpSampling2D(\n",
        "        size=(dims[-3] // x.shape[1], dims[-2] // x.shape[2]), interpolation=\"bilinear\",\n",
        "    )(x)\n",
        "\n",
        "    out_1 = convolutionBlock(dspp_input, kernel_size=1, dilation_rate=1)\n",
        "    out_6 = convolutionBlock(dspp_input, kernel_size=3, dilation_rate=6)\n",
        "    out_12 = convolutionBlock(dspp_input, kernel_size=3, dilation_rate=12)\n",
        "    out_18 = convolutionBlock(dspp_input, kernel_size=3, dilation_rate=18)\n",
        "\n",
        "    x = layers.Concatenate(axis=-1)([out_pool, out_1, out_6, out_12, out_18])\n",
        "    output = convolution_block(x, kernel_size=1)\n",
        "    return output"
      ],
      "metadata": {
        "id": "LlIQH_BmU4Mp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# DeepLab Architecture\n",
        "def DeeplabV3Plus(image_size, num_classes):\n",
        "    model_input = keras.Input(shape=(image_size, image_size, 3))\n",
        "    resnet50 = keras.applications.ResNet50(\n",
        "        weights=\"imagenet\", include_top=False, input_tensor=model_input\n",
        "    )\n",
        "    x = resnet50.get_layer(\"conv4_block6_2_relu\").output\n",
        "    x = DilatedSpatialPyramidPooling(x)\n",
        "\n",
        "    input_a = layers.UpSampling2D(\n",
        "        size=(image_size // 4 // x.shape[1], image_size // 4 // x.shape[2]),\n",
        "        interpolation=\"bilinear\",\n",
        "    )(x)\n",
        "    input_b = resnet50.get_layer(\"conv2_block3_2_relu\").output\n",
        "    input_b = convolution_block(input_b, num_filters=48, kernel_size=1)\n",
        "\n",
        "    x = layers.Concatenate(axis=-1)([input_a, input_b])\n",
        "    x = convolution_block(x)\n",
        "    x = convolution_block(x)\n",
        "    x = layers.UpSampling2D(\n",
        "        size=(image_size // x.shape[1], image_size // x.shape[2]),\n",
        "        interpolation=\"bilinear\",\n",
        "    )(x)\n",
        "    model_output = layers.Conv2D(num_classes, kernel_size=(1, 1), padding=\"same\")(x)\n",
        "    return keras.Model(inputs=model_input, outputs=model_output)\n",
        "\n",
        "\n",
        "model = DeeplabV3Plus(image_size=IMAGE_SIZE, num_classes=NUM_CLASSES)\n",
        "model.summary()\n",
        "\n",
        "loss = keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "model.compile(\n",
        "    optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
        "    loss=loss,\n",
        "    metrics=[\"accuracy\"],\n",
        ")\n",
        "\n",
        "history = model.fit(train_dataset,validation_data=val_dataset, epochs=5)"
      ],
      "metadata": {
        "id": "RHp7GXOeU8Ys"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plottig the accuracy for evaluation\n",
        "plt.plot(history.history[\"loss\"])\n",
        "plt.title(\"Training Loss\")\n",
        "plt.ylabel(\"loss\")\n",
        "plt.xlabel(\"epoch\")\n",
        "plt.show()\n",
        "\n",
        "plt.plot(history.history[\"accuracy\"])\n",
        "plt.title(\"Training Accuracy\")\n",
        "plt.ylabel(\"accuracy\")\n",
        "plt.xlabel(\"epoch\")\n",
        "plt.savefig(\"accuracy.png\")\n",
        "\n",
        "plt.plot(history.history[\"val_loss\"])\n",
        "plt.title(\"Validation Loss\")\n",
        "plt.ylabel(\"val_loss\")\n",
        "plt.xlabel(\"epoch\")\n",
        "plt.savefig(\"val_loss.png\")\n",
        "\n",
        "plt.plot(history.history[\"val_accuracy\"])\n",
        "plt.title(\"Validation Accuracy\")\n",
        "plt.ylabel(\"val_accuracy\")\n",
        "plt.xlabel(\"epoch\")\n",
        "plt.savefig(\"val_accuracy.png\")\n",
        "model.save(\"my_model\")"
      ],
      "metadata": {
        "id": "7bXZNYzoU_eH"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "ImageSegmentation.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}